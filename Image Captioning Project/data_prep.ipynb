{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_prep.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"OdOi9R-MxGtB","colab_type":"code","colab":{}},"source":["import pickle\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","from PIL import Image\n","\n","class ImageDataset(Dataset):\n","    \"\"\"MIT image dataset.\"\"\"\n","\n","    def __init__(self, root_dir, data, transform = None):\n","        self.root_dir  = root_dir\n","        self.dataPtr   = data\n","        self.transform = transform\n","        with open(self.root_dir + \"cleanTrainCap\", \"rb\") as f:\n","            self.trainCap = pickle.load(f)\n","        with open(\"cleanTrainID\", \"rb\") as f:\n","            self.trainID = pickle.load(f) - 1\n","\n","    def __len__(self):\n","        return len(self.dataPtr)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.root_dir + \"images/\" + self.dataPtr[idx]\n","        image = Image.open(img_name)\n","        if self.transform:\n","            image = self.transform(image)\n","        if image.size()[0] == 1:\n","            image = image.repeat(3,1,1)\n","\n","        elif  image.size()[0] == 4:\n","            image = image[0].repeat(3,1,1)\n","\n","        imgNum = int(self.dataPtr[idx][3:-4])\n","        captions = self.trainCap[self.trainID == imgNum]\n","        rand    = np.random.randint(captions.shape[0])\n","        caption = captions[rand]\n","\n","        sample = {'image': image, 'caption': torch.from_numpy(np.array(caption))}\n","        return sample"],"execution_count":0,"outputs":[]}]}